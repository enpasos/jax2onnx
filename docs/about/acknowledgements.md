# Acknowledgements

## Special Thanks

✨ **[@clementpoiret](https://github.com/clementpoiret)** for initiating Equinox support and for [Equimo](https://github.com/clementpoiret/equimo), which brings modern vision models—such as [DINOv3](https://ai.meta.com/dinov3/)—to JAX/Equinox.

✨ **[@justinchuby](https://github.com/justinchuby)** for introducing **onnx-ir** as a scalable and more efficient way to handle ONNX model construction.  

✨ **[@atveit](https://github.com/atveit)** for introducing us to [gpt-oss-jax-vs-torch-numerical-comparison](https://github.com/atveit/gpt-oss-jax-vs-torch-numerical-comparison).

✨ **[@benmacadam64](https://github.com/benmacadam64)** for championing the complex-number handling initiative.

✨ **[@lutzroeder](https://github.com/lutzroeder)** for making shapes internal to ONNX function visible in his great Netron viewer.
- [ONNX: Function value_info support #1447](https://github.com/lutzroeder/netron/issues/1447)

✨ **[tumaer/JAXFLUIDS](https://github.com/tumaer/JAXFLUIDS)** for contributing valuable insights rooted in physics simulation use cases.

✨ **[@limarta](https://github.com/limarta)** for the elegant [jaxpr-to-ONNX demonstration](https://gist.github.com/limarta/855a88cc1c0163487a9dc369891147ab) that inspired this project.

## Contributors

**Example contributions:** [@burakssen](https://github.com/burakssen), [@Cadynum](https://github.com/Cadynum), [@clementpoiret](https://github.com/clementpoiret), [@PVirie](https://github.com/PVirie), [@Artoriuz](https://github.com/Artoriuz)

**Plugin contributions:** [@burakssen](https://github.com/burakssen), [@clementpoiret](https://github.com/clementpoiret), [@Clouder0](https://github.com/Clouder0), [@rakadam](https://github.com/rakadam), [@benmacadam64](https://github.com/benmacadam64)

## Community

Thanks to the community members involved in:

- [Flax Feature Request #4430](https://github.com/google/flax/issues/4430)
- [JAX Feature Request #26430](https://github.com/jax-ml/jax/issues/26430)
