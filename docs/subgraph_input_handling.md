# Subgraph Input Handling in ONNX Control-Flow Operators

## ONNX **If** Operator – Subgraph Inputs and Scope

The **If** operator in ONNX is defined to accept only a single explicit input: the boolean condition (`cond`). The **then\_branch** and **else\_branch** are Graph attributes (subgraphs) that produce the operator’s outputs, and **each branch must have the same number of outputs** (N) with matching types. Crucially, **the subgraphs for an If node do not declare any additional formal inputs** beyond the condition. In other words, you cannot pass “payload” tensors into an If’s branches via the node’s input list – only the condition is passed in explicitly.

Instead, any values needed inside the then/else subgraphs must be **captured from the parent scope** (implicitly referenced by name) rather than being formally passed in. The ONNX spec permits nested subgraphs to reference outer-scope values. For example, if an outer tensor `X` is required inside the If branches, the branch GraphProtos should simply use `X` by name in their node definitions. The branch graphs’ input list remains empty, and `X` is implicitly taken from the enclosing graph’s scope (behaving like a captured variable). This design is essentially mandated by the ONNX specification for If: the operator schema defines exactly one input (the condition), so any additional data must be obtained via closure-like referencing. Attempting to declare subgraph inputs for an If (as one might in a function call) will lead to validation errors. In fact, ONNX maintainers have clarified that **If subgraphs should have no formal inputs**, and all required values should be directly used from the parent graph’s scope. This behavior is a **spec requirement**, not just an ONNX Runtime quirk – ONNX Runtime’s error messages (e.g. “Got 0 inputs but subgraph has 1 input…”) reflect the enforcement of the schema rules. In summary, for ONNX’s If operator the condition is the only explicit input, and any other needed tensors are forwarded implicitly via name capture in the subgraphs (this is the only valid way to supply them given the spec).

Most production exporters (PyTorch, TensorFlow via tf2onnx, etc.) stick to this recipe: the `If` node has a single input (`cond`), both branch graphs list zero inputs, and any tensors they reference are looked up by name in the parent graph. Trying to feed additional inputs into the node (`If(cond, x, y)`) will trip ONNX checks with errors like “input size of if-op should be 1”, so our lowering must mirror the spec-aligned exporter behaviour.

## ONNX **Loop** Operator – Subgraph Inputs and Explicit Passing

The **Loop** operator uses a different pattern: it explicitly passes required values into its subgraph (the loop body) through the node’s inputs. According to the ONNX specification, a Loop node has a variadic input list that includes: an optional max trip-count (`M`), an optional initial condition (`cond`), and **N loop-carried initial values (`v_initial`)**. Correspondingly, the Loop’s `body` Graph attribute must declare **2+N inputs**: these are **`iteration_num`**, **`condition`**, and **N loop-carried variables**. On each iteration, the runtime will feed the iteration count and the current loop-carried values into the body subgraph, along with the loop’s running condition. The body subgraph produces **1+N+K outputs**: a loop condition for continuation, N updated loop-carried values, and K “scan” outputs (values accumulated across iterations). All these outputs are explicitly mapped back to the Loop node’s outputs (the final loop-carried values and concatenated scan results).

Importantly, **any tensor that the loop body needs must be provided through these inputs** (or be a constant/initializer). The ONNX spec effectively requires the loop body’s data dependencies to be explicit. For example, if an outer-scope tensor is needed inside the loop and is not one of the loop-carried variables, a typical pattern is to add it as a loop-carried dependency that doesn’t change – passing it in via `v_initial` and carrying it through each iteration unchanged. (In practice, an outer constant could also be directly used inside as an initializer, but any *dynamic* outer value should flow in through the formal inputs.) This design ensures the loop subgraph’s interface is well-defined: **the Loop operator’s inputs forward all necessary values explicitly**. The ONNX loop schema spells out the exact input ordering and count that the subgraph must adhere to, and ONNX Runtime will enforce that the number and types match. While the ONNX spec doesn’t explicitly forbid referencing an outer scope variable inside a Loop body, the formal model encourages explicit input passing for everything the loop uses (aside from truly constant values). In summary, **Loop’s body subgraph expects all needed data as explicit inputs from the parent** – the iteration counter, loop condition, and any state or external values should be part of the input list provided by the Loop node. This is a clear requirement from the ONNX operator definition, not merely an implementation detail.

## ONNX **Scan** Operator – Subgraph Inputs and Explicit Passing

The **Scan** operator (which iterates over one or more sequences, akin to a functional scan or RNN loop) follows a similar explicit input passing convention as Loop. The ONNX spec defines that a Scan’s `body` Graph has **N+M inputs** and **N+K outputs**. Here, **N** represents the number of state variables carried through iterations (like loop-carried dependencies), and **M** is the number of sequence elements fed in each iteration (from M scan-input sequences). Specifically, at each iteration the Scan subgraph is given the current values of all N state variables and the next element of each of the M scan input tensors. It produces updated state variables and K output values (each corresponding to a “scan output element”) which will be concatenated or stacked to form the final scan outputs across iterations. The ONNX **Scan** operator’s node inputs are defined to supply exactly those required values: the initial state tensors followed by all the scan input sequences. Thus, **all data needed inside the Scan body is forwarded explicitly via the operator’s inputs**. As with Loop, if a value from the outer scope is needed in the Scan computation, it should be passed in as either a state variable (that perhaps remains constant) or as a scan input (if it’s sequence data) in the node’s input list. The body GraphProto must list its inputs in the order of state variables and iterated elements, matching what the Scan node provides. ONNX’s official documentation makes this interface clear by describing the body graph’s inputs as “(loop state variables…, scan\_input\_elts…)” for each iteration. Like Loop, **Scan’s subgraph does not implicitly capture outer graph values** – it relies on the parent node to hand in everything needed as parameters. This is dictated by the ONNX Scan schema and enforced by tools/runtimes. In essence, Scan is consistent with Loop in that **its subgraph input handling is fully explicit** and determined by the operator specification (N state inputs + M data inputs per iteration).

## Specification vs. Implementation: ONNX Standard Behavior

The above patterns are **mandated by the ONNX specification** (as defined in the operator schemas and documentation), rather than being left to implementation choice. The ONNX standard’s Operators definitions (in the official `Operators.md` and schema for each op) lay out how subgraph inputs/outputs must be structured for control-flow ops. For instance, the spec explicitly defines the signature of Loop’s body graph and Scan’s body graph in terms of inputs and outputs counts/order. In the case of If, the schema restricts the node’s inputs to one, implying no additional explicit inputs for branches. While the *written* spec lacked an explicit statement that If subgraphs must have empty input lists, this is an understood requirement derived from the schema and was confirmed by ONNX maintainers. All major ONNX-compatible runtimes (ONNX Runtime, etc.) implement these rules as part of model checking and execution. The ONNX Runtime, for example, will raise errors if a subgraph’s declared inputs don’t align with the main node’s provided inputs (or lack thereof) – as seen in user reports when an If subgraph was incorrectly given an input, causing a shape inference failure. In summary, the handling of subgraph inputs for If/Loop/Scan is consistent with the ONNX spec’s design. ONNX Runtime and other frameworks simply enforce what the spec dictates. There is no variation by runtime – any deviation (such as trying to pass extra inputs into an If branch) is invalid in ONNX and will be rejected. The distinction is thus spec-defined: If’s design vs. Loop/Scan’s design, rather than an arbitrary implementation detail.

## Comparison of Patterns Across **If**, **Loop**, and **Scan**

Although all three operators use nested subgraphs, their input-handling patterns differ by design:

* **ONNX If:** *Implicit input capture.* The If node strictly takes only the condition as an input. Therefore, its branch subgraphs cannot have formal parameters for other values. This results in a pattern where **any tensor needed inside the branches is implicitly captured from the outer scope** by name. The outer value becomes visible in the subgraph without explicit wiring. This is a unique, closure-like behavior in ONNX’s model. It is **not optional** – it’s the only way to supply extra data to an If branch given the one-input schema. In practice, this means If’s subgraphs behave a bit like code blocks that inherently share the outer context (aside from the condition which is passed in).

* **ONNX Loop:** *Explicit input passing.* The Loop operator defines a clear interface for its body: iteration index, loop condition, and loop-carried tensors are all passed in every iteration. All necessary values must be accounted for in those inputs or be constant. In other words, **Loop enforces that data flows into and out of the subgraph through the defined parameters** (the loop-carried dependencies and scan inputs/outputs). There isn’t a mechanism to magically “see” other outer graph values unless you explicitly include them as loop inputs. This makes the loop body graph more like a function with a fixed signature. The handling here is strict: the parent Loop node’s input list and the subgraph’s input list must align exactly in number and semantics.

* **ONNX Scan:** *Explicit input passing (similar to Loop).* Scan’s body likewise receives explicit inputs for state and sequence elements. It follows the same philosophy as Loop – define all required inputs up front. The scan body does not automatically inherit any outer context except via those inputs. So, **Scan’s subgraph input handling is consistent with Loop’s approach**, differing only in the specific meaning of inputs (sequence element vs. loop index, etc.).

**In summary, ONNX is consistent in enforcing well-defined interfaces for control-flow subgraphs**, but the nature of the interface differs: **If** has a minimalist interface (just the condition) and thereby forces an implicit capture of other values, whereas **Loop and Scan** have a richer interface that explicitly conveys all needed information each iteration. This is by design in the ONNX spec. All control-flow operators require that their subgraph’s inputs match what the outer node provides – there is no support for arbitrary extra inputs beyond those definitions. In that sense, the “strictness” is universal: each operator’s contract must be respected exactly. The **If operator’s strictness manifests as forbidding any subgraph inputs (besides the condition)**, effectively demanding implicit forwarding. **Loop and Scan’s strictness manifests as requiring all subgraph inputs to be explicitly listed and passed**. Thus, the mechanism differs, but in all cases the dataflow between parent and subgraph is tightly governed by the ONNX specification (and enforced by ONNX Runtime).

**Sources:** Official ONNX operator specifications for If, Loop, and Scan, ONNX issue discussions and documentation clarifying subgraph input rules, and ONNX community explanations of nested graph scope handling.
