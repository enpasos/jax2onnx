from pathlib import Path
import time
import logging
import subprocess
import json
from typing import Any, Dict, List, Tuple
from tests.t_generator import (
    load_plugin_metadata,
    get_plugin_grouping,
    organize_tests_by_context_and_component_from_params,
)

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(message)s")

# Paths
BASE_DIR = Path(__file__).parent
README_PATH = BASE_DIR / "../README.md"
REPORT_PATH = BASE_DIR / "output/pytest_report.json"
REPORT_PATH.parent.mkdir(parents=True, exist_ok=True)  # Ensure output dir exists

# Markers for auto-generated sections in README.md
START_MARKER = "<!-- AUTOGENERATED TABLE START -->"
END_MARKER = "<!-- AUTOGENERATED TABLE END -->"
EXAMPLES_START_MARKER = "<!-- AUTOGENERATED EXAMPLES TABLE START -->"
EXAMPLES_END_MARKER = "<!-- AUTOGENERATED EXAMPLES TABLE END -->"

NETRON_BASE_URL = "https://netron.app/?url=https://enpasos.github.io/jax2onnx/onnx/"


# --- Running Tests ---
def run_pytest() -> Dict[Tuple[str, str, str], str]:
    """Runs pytest and captures test results."""
    logging.info("üõ† Running tests...")

    # try:
    #     subprocess.run(
    #         ["pytest", "--json-report", f"--json-report-file={REPORT_PATH}"],
    #         capture_output=True,
    #         text=True,
    #         check=True,
    #     )
    # except subprocess.CalledProcessError as e:
    #     logging.error(f"‚ùå Pytest execution failed: {e}")
    #     return {}

    return parse_pytest_results()


def parse_pytest_results() -> Dict[Tuple[str, str, str], str]:
    """Parses pytest JSON report and extracts test results."""
    if not REPORT_PATH.exists():
        logging.warning("‚ö†Ô∏è No pytest report found.")
        return {}

    with REPORT_PATH.open("r", encoding="utf-8") as f:
        data = json.load(f)

    test_results = {}
    for test in data.get("tests", []):
        partA, partB, partC = test["nodeid"].split("::")
        partAs = partA.split("/")
        testcase_name = (
            partC.replace("test_", "") if partC.startswith("test_") else partC
        )
        situation = partAs[1]  # expecting "examples" or "primitives"
        context = partAs[-1]

        context = (
            context.replace("test_", "") if context.startswith("test_") else context
        )
        context = context.replace(".py", "") if context.endswith(".py") else context
        context = situation + "." + context
        plugin = partB.replace("Test_", "") if partB.startswith("Test_") else partB

        status = "‚úÖ" if test["outcome"] == "passed" else "‚ùå"
        key = (context, plugin, testcase_name)
        test_results[key] = status

    logging.info(f"‚úÖ {len(test_results)} test results captured.")
    return test_results


# --- Metadata Processing ---
def merge_test_results(
    grouped: Dict[Tuple[str, str], List[Dict[str, Any]]], test_results: Dict
) -> Dict[Tuple[str, str], List[Dict[str, Any]]]:
    """Ensures all metadata appears in tables, even if no test result exists."""
    for (context, component), testcases in grouped.items():
        for tc in testcases:
            tc_name = tc["testcase"]
            result = test_results.get(
                (context, component, tc_name), "‚ûñ"
            )  # Always set a result
            url = f"{NETRON_BASE_URL}{context.replace('.', '/')}/{tc_name}.onnx"
            tc["result"] = f"[`{tc_name}`]({url}) {result}"

    logging.info(
        f"üìå Merged {len(grouped)} grouped metadata entries with test results."
    )
    return grouped


# --- README Update ---
def update_readme(
    grouped_metadata: Dict[Tuple[str, str], List[Dict[str, Any]]], test_results: Dict
):
    """Updates README.md with new plugin and example tables."""
    plugins_grouped = {
        k: v for k, v in grouped_metadata.items() if k[0].startswith("primitives")
    }
    examples_grouped = {
        k: v for k, v in grouped_metadata.items() if k[0].startswith("examples")
    }

    plugins_grouped = merge_test_results(plugins_grouped, test_results)
    examples_grouped = merge_test_results(examples_grouped, test_results)

    new_plugins_section = generate_markdown_table(plugins_grouped, is_example=False)
    new_examples_section = generate_markdown_table(examples_grouped, is_example=True)

    readme_content = README_PATH.read_text(encoding="utf-8")

    readme_content = replace_markers(
        readme_content, START_MARKER, END_MARKER, new_plugins_section
    )
    readme_content = replace_markers(
        readme_content, EXAMPLES_START_MARKER, EXAMPLES_END_MARKER, new_examples_section
    )

    README_PATH.write_text(readme_content, encoding="utf-8")
    logging.info("‚úÖ README.md updated successfully!")


def generate_markdown_table(
    grouped: Dict[Tuple[str, str], List[Dict[str, Any]]], is_example: bool
) -> str:
    """Generates markdown table for README, ensuring all metadata is included."""
    if is_example:
        header = (
            "| Component | Description | Children | Testcases | Since |\n"
            "|:----------|:------------|:---------|:---------|:------|"
        )
        rows = []
        for (context, component), data in sorted(grouped.items()):
            description = data[0].get("description", "‚ûñ")
            children = data[0].get("children", [])
            children_str = "<br>".join(children) if children else "‚ûñ"
            testcases_str = "<br>".join(tc["result"] for tc in data) if data else "‚ûñ"
            since = data[0].get("since", "‚ûñ")  # Ensure "since" is included
            row = f"| {component} | {description} | {children_str} | {testcases_str} | {since} |"
            rows.append(row)

    else:
        header = (
            "| JAX Component | ONNX Components | Testcases | Since |\n"
            "|:-------------|:---------------|:---------|:------|"
        )
        rows = []
        for (context, component), data in sorted(grouped.items()):
            comp_name = component.removeprefix("plugins.")
            jax_comp = f"[{comp_name}]({data[0]['jax_doc']})"
            onnx_components = (
                "<br>".join(
                    sorted([f"[{x['component']}]({x['doc']})" for x in data[0]["onnx"]])
                )
                if data[0]["onnx"]
                else "‚ûñ"
            )
            testcases_str = "<br>".join(tc["result"] for tc in data) if data else "‚ûñ"
            since = data[0].get("since", "‚ûñ")
            row = f"| {jax_comp} | {onnx_components} | {testcases_str} | {since} |"
            rows.append(row)

    logging.info(f"üìã Generated {len(rows)} table rows.")
    return f"{header}\n" + "\n".join(rows)


def replace_markers(
    content: str, start_marker: str, end_marker: str, new_section: str
) -> str:
    """Replaces section between markers in README.md, ensuring no data loss."""
    start_idx = content.find(start_marker)
    end_idx = content.find(end_marker)
    if start_idx == -1 or end_idx == -1:
        logging.error(
            f"‚ùå Markers `{start_marker}` or `{end_marker}` not found in README.md"
        )
        return content

    return (
        content[:start_idx]
        + f"{start_marker}\n\n{new_section}\n\n{end_marker}"
        + content[end_idx + len(end_marker) :]
    )


# --- Main Execution ---
if __name__ == "__main__":
    start_time = time.time()
    test_results = run_pytest()
    grouped_metadata = get_plugin_grouping()
    update_readme(grouped_metadata, test_results)
    logging.info(f"‚è≥ Total execution time: {time.time() - start_time:.2f}s")
